\# 📘 머신러닝 학습 기록



\## 📌 주제: 서포트 벡터 머신 (SVM)



\### 2025.09.26



\#### SVM 개요

\- \*\*정의\*\*: 서포트 벡터 머신(Support Vector Machine; SVM)은 선형/비선형 \*\*분류\*\*, \*\*회귀\*\*, \*\*특이치 탐지\*\*까지 가능한 다목적 모델.

\- \*\*장점\*\*: 중소규모의 비선형 데이터셋, 특히 분류 작업에 강력함.

\- \*\*단점\*\*: 매우 큰 데이터셋에는 확장성이 떨어지고, 특성 수가 많을 때도 학습 시간이 오래 걸릴 수 있음.



---



\#### 5.1 선형 SVM 분류

\- \*\*Large Margin Classification (라지 마진 분류)\*\*  

&nbsp; 클래스 사이에서 \*\*가장 폭이 넓은 결정 경계\*\*(마진)를 찾는 방향으로 학습.

\- \*\*Support Vector (서포트 벡터)\*\*  

&nbsp; 결정 경계와 가장 가까이 위치해, 경계를 “지지”하는 샘플.

\- \*\*주의점\*\*:  

&nbsp; - SVM은 \*\*특성 스케일에 민감\*\* → 반드시 표준화(스케일링) 필요.  

&nbsp; - 스케일을 다르게 하면 결정 경계가 크게 바뀔 수 있음.



---



\#### 5.1.1 소프트 마진 분류

\- \*\*Hard Margin Classification\*\*  

&nbsp; - 모든 샘플이 경계 바깥쪽에 올바르게 분류되어야 함.  

&nbsp; - 하지만 \*\*데이터가 선형적으로 구분 가능해야만 작동\*\*하며, \*\*이상치에 매우 민감\*\*.  



\- \*\*Soft Margin Classification\*\*  

&nbsp; - 경계의 폭을 넓게 유지하면서 일부 마진 오류를 허용.  

&nbsp; - \*\*규제 하이퍼파라미터 C\*\*  

&nbsp;   - `C ↑` → 마진 오류 줄이려 함 (결정 경계가 타이트해짐, 과대적합 위험↑)  

&nbsp;   - `C ↓` → 마진 오류 허용 (결정 경계가 넓어짐, 과소적합 위험↑)  



---



\#### 파이썬 코드 예제

```python

from sklearn.datasets import load\_iris

from sklearn.pipeline import make\_pipeline

from sklearn.preprocessing import StandardScaler

from sklearn.svm import LinearSVC



\# 데이터셋 로드: 붓꽃(iris) 데이터

iris = load\_iris(as\_frame=True)



\# 특성 선택: 꽃잎 길이와 꽃잎 너비만 사용

X = iris.data\[\["petal length (cm)", "petal width (cm)"]].values

\# 타겟 설정: Iris-Virginica 여부 (이진 분류)

y = (iris.target == 2)



\# SVM 분류기 생성: 표준화 + Linear SVM

svm\_clf = make\_pipeline(

&nbsp;   StandardScaler(),   # 특성 스케일링 (SVM에서 필수적)

&nbsp;   LinearSVC(C=1, random\_state=42)  # C=1, 선형 SVM

)



\# 모델 학습

svm\_clf.fit(X, y)



실행 예제



\# 새로운 샘플 2개

X\_new = \[\[5.5, 1.7], \[5.0, 1.5]]



\# 예측 (True = Iris-Virginica, False = Virginica 아님)

print(svm\_clf.predict(X\_new))



예상 출력



\[ True False ]

(첫 번째 샘플은 Virginica, 두 번째는 Virginica 아님)



모델 평가

\# decision\_function: 각 샘플의 결정 함수 값 (경계로부터의 거리)

print(svm\_clf.decision\_function(X\_new))



예상 출력

\[ 1.8 -0.6 ]



양수 값 → Virginica 클래스에 속할 가능성이 큼



음수 값 → Virginica 클래스가 아님



값의 크기 → 결정 경계로부터의 거리 (마진)



추가 설명



LinearSVC는 선형 SVM 구현체이며, 대규모 데이터셋에서 효율적.



커널 기법을 사용한 비선형 분류(SVC with kernel="rbf")와는 다름.



실제 데이터셋에서는 StandardScaler를 반드시 사용하는 습관이 중요.

